{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67afa651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#predicting the probability of a binary outcome using the logistic function\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#c measuring the proportion of correctly classified instances in a classification model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1de4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loarding data set\n",
    "data = pd.read_csv(\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d430b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6842352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for missing values\n",
    "sns.heatmap(data.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae1227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#co relation matrix\n",
    "correlation = data.corr()\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b5bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation, annot=True, fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b1666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X = data.drop(\"Outcome\",axis = 1)\n",
    "Y = data['Outcome']\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95051b30",
   "metadata": {},
   "source": [
    "# Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ed7919",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a997d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9ddcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(prediction,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ee1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5add1ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "joblib.dump(model, 'trained_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1d3d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression with cross-validation\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_accuracies = cross_val_score(lr_model, X, Y, cv=10)  # 10-fold cross-validation\n",
    "\n",
    "# Display cross-validation accuracies and the best accuracy\n",
    "print(\"Logistic Regression Cross-Validation Accuracies:\", lr_accuracies)\n",
    "print(\"Best Logistic Regression Accuracy:\", max(lr_accuracies))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9466c516",
   "metadata": {},
   "source": [
    "# Logistic Regression with improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf66cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Loading dataset\n",
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "# Train-test split\n",
    "X = data.drop(\"Outcome\", axis=1)\n",
    "Y = data['Outcome']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid.best_estimator_\n",
    "prediction = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(Y_test, prediction)\n",
    "\n",
    "# Output\n",
    "print(\"Best Hyperparameters:\", grid.best_params_)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c701da",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e19d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing the Random Forest classifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Training the Random Forest model\n",
    "# rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# rf_model.fit(X_train, Y_train)\n",
    "\n",
    "# # Making predictions\n",
    "# rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# # Calculating accuracy\n",
    "# rf_accuracy = accuracy_score(rf_predictions, Y_test)\n",
    "\n",
    "# # Displaying predictions and accuracy\n",
    "# print(rf_predictions)\n",
    "# print(rf_accuracy)\n",
    "\n",
    "# # Save the trained Random Forest model to a file\n",
    "# # joblib.dump(rf_model, 'rf_trained_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0023d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest with cross-validation\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_accuracies = cross_val_score(rf_model, X, Y, cv=10)  # 10-fold cross-validation\n",
    "\n",
    "# Display cross-validation accuracies and the best accuracy\n",
    "print(\"Random Forest Cross-Validation Accuracies:\", rf_accuracies)\n",
    "print(\"Best Random Forest Accuracy:\", max(rf_accuracies))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cb4d53",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2de402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Training the Decision Tree model\n",
    "# dt_model = DecisionTreeClassifier(random_state=42)\n",
    "# dt_model.fit(X_train, Y_train)\n",
    "\n",
    "# # Making predictions\n",
    "# dt_predictions = dt_model.predict(X_test)\n",
    "\n",
    "# # Calculating accuracy\n",
    "# dt_accuracy = accuracy_score(dt_predictions, Y_test)\n",
    "\n",
    "# # Displaying predictions and accuracy\n",
    "# print(\"Decision Tree Predictions:\", dt_predictions)\n",
    "# print(\"Decision Tree Accuracy:\", dt_accuracy)\n",
    "\n",
    "# # Save the trained Decision Tree model\n",
    "# # joblib.dump(dt_model, 'dt_trained_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9313bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Decision Tree with cross-validation\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_accuracies = cross_val_score(dt_model, X, Y, cv=10)  # 10-fold cross-validation\n",
    "\n",
    "# Display cross-validation accuracies and the best accuracy\n",
    "print(\"Decision Tree Cross-Validation Accuracies:\", dt_accuracies)\n",
    "print(\"Best Decision Tree Accuracy:\", max(dt_accuracies))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a69875a",
   "metadata": {},
   "source": [
    "# Stack Ensemble (Final Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03c9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Load the Pima Indian Diabetes dataset\n",
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "# Features and target variable\n",
    "X = data.drop(\"Outcome\", axis=1)\n",
    "Y = data['Outcome']\n",
    "\n",
    "# Base learners\n",
    "base_learners = [\n",
    "    ('logreg', LogisticRegression(max_iter=1000)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "\n",
    "# Meta-model (XGBClassifier)\n",
    "meta_model = XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "# Stacking ensemble\n",
    "stacking_model = StackingClassifier(estimators=base_learners, final_estimator=meta_model)\n",
    "\n",
    "# Apply cross-validation\n",
    "cv_scores = cross_val_score(stacking_model, X, Y, cv=20, scoring='accuracy') # 20-fold cross-validation\n",
    "\n",
    "# Display cross-validation results and the best accuracy\n",
    "print(\"Cross-validation Accuracy Scores for Stacking Model:\", cv_scores)\n",
    "print(\"Best Stacking Model Accuracy:\", max(cv_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d27907a",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adad832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "# Count the occurrences of each value in the 'Outcome' column\n",
    "outcome_counts = data['Outcome'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Count of each class in the Outcome column:\")\n",
    "print(outcome_counts)\n",
    "\n",
    "# Plot the bar chart with specified bar colors\n",
    "plt.bar(outcome_counts.index, outcome_counts.values, color=['#4CAF50', '#F44336'], edgecolor='black')\n",
    "plt.xticks([0, 1], ['Non-Diabetic (0)', 'Diabetic (1)'])\n",
    "plt.title(\"Distribution of Outcome Column\")\n",
    "\n",
    "# Add value labels inside the bars\n",
    "for i, value in enumerate(outcome_counts.values):\n",
    "    plt.text(i, value - 20, str(value), color='white', ha='center', va='center', fontsize=10)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab22d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Fit the stacking model\n",
    "stacking_model.fit(X, Y)\n",
    "\n",
    "# Predict the outcomes\n",
    "y_pred = stacking_model.predict(X)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(Y, y_pred)\n",
    "\n",
    "# Display confusion matrix with a title\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=stacking_model.classes_)\n",
    "cm_display.plot(cmap='Blues', values_format='d')\n",
    "plt.title(\"Confusion Matrix for Stacking Model\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b580ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Fit the stacking model\n",
    "stacking_model.fit(X, Y)\n",
    "\n",
    "# Predict probabilities for the ROC curve\n",
    "y_prob = stacking_model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(Y, y_prob)\n",
    "\n",
    "# Compute AUC score\n",
    "auc_score = roc_auc_score(Y, y_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='b', label=f'ROC curve (AUC = {auc_score:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Diagonal line (no skill)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Stacking Model')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f1c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Fit the stacking model\n",
    "stacking_model.fit(X, Y)\n",
    "\n",
    "# Predict the outcomes\n",
    "y_pred = stacking_model.predict(X)\n",
    "\n",
    "# Calculate Precision, Recall, and F1-score\n",
    "precision = precision_score(Y, y_pred)\n",
    "recall = recall_score(Y, y_pred)\n",
    "f1 = f1_score(Y, y_pred)\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "metrics_data = {\n",
    "    'Metric': ['Precision', 'Recall', 'F1-score'],\n",
    "    'Value': [precision, recall, f1]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "\n",
    "# Display the table\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971c0d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Fit the ensemble model (stacking_model)\n",
    "stacking_model.fit(X, Y)\n",
    "\n",
    "# Predict the outcomes\n",
    "y_pred = stacking_model.predict(X)\n",
    "\n",
    "# Generate the classification report with meaningful labels\n",
    "report = classification_report(Y, y_pred, target_names=['Non-Diabetic', 'Diabetic'])\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Classification Report for Ensemble Model:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a69f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Fit the stacking model\n",
    "stacking_model.fit(X, Y)\n",
    "\n",
    "# Predict the outcomes\n",
    "y_pred = stacking_model.predict(X)\n",
    "\n",
    "# Calculate Precision, Recall, and F1-score\n",
    "precision = precision_score(Y, y_pred)\n",
    "recall = recall_score(Y, y_pred)\n",
    "f1 = f1_score(Y, y_pred)\n",
    "\n",
    "# Metrics for plotting\n",
    "metrics = ['Precision', 'Recall', 'F1-score']\n",
    "values = [precision, recall, f1]\n",
    "\n",
    "# Plot the metrics in a bar graph\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(metrics, values, color=['darkblue', 'orange', 'green'], width=0.4)  # Reduced bar width\n",
    "\n",
    "# Add values inside the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval / 2, f'{yval:.2f}', ha='center', va='center', color='white', fontsize=12)\n",
    "\n",
    "# Adjust spacing between bars\n",
    "plt.subplots_adjust(left=0.2, right=0.8)\n",
    "\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Precision, Recall, and F1-score for Stacking Model')\n",
    "plt.ylim([0, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edfba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "models = ['Logistic Regression', 'Random Forest', 'Decision Tree', 'Ensemble Model']\n",
    "accuracies = [82.89, 84.42, 80.52, 92.30]\n",
    "\n",
    "colors = [\"#FF6F61\", \"#FFD54F\", \"#FFCC80\", \"#4CAF50\"]\n",
    "\n",
    "# Plotting with adjusted bar width\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(models, accuracies, color=colors, width=0.5)\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Model Accuracy Comparison', fontsize=14)\n",
    "plt.xlabel('Models', fontsize=12)\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Display values in the middle of the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval/2, round(yval, 2), \n",
    "             ha='center', va='center', color='black', fontsize=12)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
